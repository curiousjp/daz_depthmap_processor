# Structuring Stable Diffusion output with Daz3D, ControlNet and Regional Prompting

This post discusses a workflow (with some variations) for taking scenes posed in Daz3D and bringing them for "rendering" in the A1111 Stable Diffusion front-end. The goal for the process is to compensate for the general lack of emphasis on composition in the training of Stable Diffusion models.

The workflow has several steps. I will demonstrate them with three examples of increasing complexity.

## Example one - a simple scene
Here, I have posed a simple scene with a character and prop, and some minor background geometry.
